{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT 19: Homework 4 Assignment - SVMs, Trees, RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "The goal of this homework is to review and bring together what we have learned about Support Vector Machines, Decision Trees, Random Forests, and ensembles. \n",
    "\n",
    "Please do all your analysis to answer the questions below in this Jupyter notebook. Show your work.\n",
    "\n",
    "**Please submit your completed notebook by 6:30PM on Wednesday, February 17.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "Use the cancer_uci.csv dataset in the Data directory of our course repo. This is the [Breast Cancer Wisconsin](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)) dataset from the UCI ML Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Load the data and check for balance between the two classes. If the ratio is less than 60/40 rebalance the classes to 50/50. We've provided some help here to get you started.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign       458\n",
      "Malignant    241\n",
      "Name: Class, dtype: int64\n",
      "Benign       0.655222\n",
      "Malignant    0.344778\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "canc = pd.read_csv(\"../data/cancer_uci.csv\", index_col=0)\n",
    "canc.head()\n",
    "print(str(canc.Class.value_counts()))\n",
    "print(str(canc.Class.value_counts('Benign')))\n",
    "#I have no idea how the second statement gave me that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have imbalanced classes so we need to decide if we want to undersample, and take only 241 values from the Benign category, or oversample, and artificially inflate the volume of malignant data. First, let's convert to binary 1,0 for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    458\n",
       "1    241\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canc.Class = canc.Class.map({'Benign':0,'Malignant':1})\n",
    "canc.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To undersample, we would throw away almost half of our benign examples, which would greatly alter our dataset and we don't want to lose that much info. So let's oversample! Here is a pattern for how to oversample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    458\n",
       "0    458\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate your two classes:\n",
    "mal_example = canc[canc.Class == 1]\n",
    "benign_example = canc[canc.Class == 0]\n",
    "\n",
    "# Oversample the malignant class to have a 50/50 ratio:\n",
    "mal_over_example = mal_example.sample(458,replace=True)\n",
    "\n",
    "# Recombine the two frames:\n",
    "over_sample = pd.concat([mal_over_example,benign_example])\n",
    "\n",
    "# Sanity check the length:\n",
    "print len(over_sample)\n",
    "over_sample.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 916 entries, 184 to 695\n",
      "Data columns (total 11 columns):\n",
      "Sample_code_number             916 non-null int64\n",
      "Clump_Thickness                916 non-null int64\n",
      "Uniformity_of_Cell_Size        916 non-null int64\n",
      "Uniformity_of_Cell_Shape       916 non-null int64\n",
      "Marginal_Adhesion              916 non-null int64\n",
      "Single_Epithelial_Cell_Size    916 non-null int64\n",
      "Bare_Nuclei                    916 non-null object\n",
      "Bland_Chromatin                916 non-null int64\n",
      "Normal_Nucleoli                916 non-null int64\n",
      "Mitoses                        916 non-null int64\n",
      "Class                          916 non-null int64\n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 85.9+ KB\n"
     ]
    }
   ],
   "source": [
    "over_sample.info()\n",
    "\n",
    "#'Bare_Nuclei' has 17 instances of non-numerical '?' \n",
    "over_sample['Bare_Nuclei'].value_counts()\n",
    "\n",
    "#Not sure if should drop or convert to mean... Gonna drop them\n",
    "over_sample = over_sample[over_sample['Bare_Nuclei'] != '?']\n",
    "over_sample['Bare_Nuclei'] = over_sample['Bare_Nuclei'].astype(float)\n",
    "\n",
    "#over_sample['Bare_Nuclei'].replace(to_replace='nan')\n",
    "#over_sample['Bare_Nuclei'] = over_sample['Bare_Nuclei'].fillna(over_sample['Bare_Nuclei'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Are the features normalized? If not, use the scikit-learn standard scaler to normalize them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "bc_feature_cols = over_sample.drop(['Class','Sample_code_number'], axis=1)\n",
    "bc_features = scaler.fit_transform(bc_feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Train a linear SVM, using the cross validated accuracy as the score (use the scikit-learn method).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97452854261843025"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#bc_features = over_sample.drop(['Class','Sample_code_number'], axis=1)\n",
    "bc_target = over_sample['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bc_features, bc_target, test_size=.20, random_state=0)\n",
    "\n",
    "\n",
    "svc_classifier = svm.SVC(kernel='linear', C=1)\n",
    "svc_clf_fit = svc_classifier.fit(X_train,y_train)\n",
    "predictions = svc_clf_fit.predict(X_test)\n",
    "\n",
    "\n",
    "cv_accuracy_score = cross_val_score(svc_classifier, bc_features, bc_target, cv=10).mean()\n",
    "cv_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Display the confusion matrix, classification report, and AUC.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.97        93\n",
      "          1       0.98      0.97      0.97        88\n",
      "\n",
      "avg / total       0.97      0.97      0.97       181\n",
      "\n",
      "0.972201857283\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Benign</th>\n",
       "      <th>Actual Malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Benign</th>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Malignant</th>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Actual Benign  Actual Malignant\n",
       "Predicted Benign                91                 2\n",
       "Predicted Malignant              3                85"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,predictions))\n",
    "print(roc_auc_score(y_test,predictions))\n",
    "cm = confusion_matrix(y_test,predictions)\n",
    "cm_df = pd.DataFrame(cm, index=['Predicted Benign', 'Predicted Malignant'], \n",
    "                     columns=['Actual Benign', 'Actual Malignant'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Repeat steps 2 through 4 using a Decision Tree model. Are the results better or worse than the SVM?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95789795722379978"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "tree_clf_fit = tree_clf.fit(X_train, y_train)\n",
    "tree_predictions = tree_clf_fit.predict(X_test)\n",
    "\n",
    "tree_cross_val_accuracy = cross_val_score(tree_clf, bc_features, bc_target, cv=10).mean()\n",
    "tree_cross_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.94      0.96        93\n",
      "          1       0.93      0.98      0.96        88\n",
      "\n",
      "avg / total       0.96      0.96      0.96       181\n",
      "\n",
      "0.95637829912\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Benign</th>\n",
       "      <th>Actual Malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Benign</th>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Malignant</th>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Actual Benign  Actual Malignant\n",
       "Predicted Benign                87                 6\n",
       "Predicted Malignant              2                86"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test,tree_predictions))\n",
    "print(roc_auc_score(y_test, tree_predictions))\n",
    "cm = confusion_matrix(y_test,tree_predictions)\n",
    "cm_df = pd.DataFrame(cm, index=['Predicted Benign', 'Predicted Malignant'], \n",
    "                     columns=['Actual Benign', 'Actual Malignant'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are worse than the SVM, but the Decision Tree was not optimized. Also, \"was this model better or worse\" is a bit of a trick question-- in my opinion, we care more about false negatives (predicted benign, actually malignant) than false positives (predicted malignant, actually benign)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Repeat steps 2 through 4 using a Random Forest model. Are the results better or worse than the SVM?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98341825465420984"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=5, n_estimators=100, max_features=3)\n",
    "rf_clf_fit = rf_clf.fit(X_train,y_train)\n",
    "\n",
    "rf_predictions = rf_clf_fit.predict(X_test)\n",
    "\n",
    "rf_cross_val_accuracy = cross_val_score(rf_clf, bc_features, bc_target, cv=10).mean()\n",
    "rf_cross_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99        93\n",
      "          1       0.98      1.00      0.99        88\n",
      "\n",
      "avg / total       0.99      0.99      0.99       181\n",
      "\n",
      "0.989247311828\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Benign</th>\n",
       "      <th>Actual Malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Benign</th>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Malignant</th>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Actual Benign  Actual Malignant\n",
       "Predicted Benign                91                 2\n",
       "Predicted Malignant              0                88"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test,rf_predictions))\n",
    "print(roc_auc_score(y_test, rf_predictions))\n",
    "cm = confusion_matrix(y_test,rf_predictions)\n",
    "cm_df = pd.DataFrame(cm, index=['Predicted Benign', 'Predicted Malignant'], \n",
    "                     columns=['Actual Benign', 'Actual Malignant'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than the Decision Tree model on both counts, and has fewer false positives than the SVM model. Same number of false negatives, however. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Credit Questions\n",
    "**The following questions are strongly encouraged, but not required for this homework assignment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) Combine the SVM and the Decision Tree model using the [Voting Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html). Are the results better than either of these base classifiers alone?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970096308186\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.97        93\n",
      "          1       0.98      0.97      0.97        88\n",
      "\n",
      "avg / total       0.97      0.97      0.97       181\n",
      "\n",
      "0.972201857283\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Benign</th>\n",
       "      <th>Actual Malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Benign</th>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Malignant</th>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Actual Benign  Actual Malignant\n",
       "Predicted Benign                91                 2\n",
       "Predicted Malignant              3                85"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = tree_clf \n",
    "clf2 = svc_classifier \n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('Decision Tree', clf1), ('SVM', clf2)], voting='hard')\n",
    "voting_clf_fit = voting_clf.fit(bc_features, bc_target)\n",
    "vot_predictions = voting_clf_fit.predict(X_test)\n",
    "voting_cross_val_accuracy = cross_val_score(voting_clf, bc_features, bc_target, cv=10).mean()\n",
    "\n",
    "print(str((voting_cross_val_accuracy)))\n",
    "print(classification_report(y_test,vot_predictions))\n",
    "print(roc_auc_score(y_test, vot_predictions))\n",
    "cm = confusion_matrix(y_test,vot_predictions)\n",
    "cm_df = pd.DataFrame(cm, index=['Predicted Benign', 'Predicted Malignant'], \n",
    "                     columns=['Actual Benign', 'Actual Malignant'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same overall performance as the SVM model, better than the Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8) Train an SVM using the RBF kernel. Is this model better or worse?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.974528542618\n",
      "[[90  3]\n",
      " [ 2 86]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.97      0.97        93\n",
      "          1       0.97      0.98      0.97        88\n",
      "\n",
      "avg / total       0.97      0.97      0.97       181\n",
      "\n",
      "0.972507331378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Benign</th>\n",
       "      <th>Actual Malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Benign</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Malignant</th>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Actual Benign  Actual Malignant\n",
       "Predicted Benign                90                 3\n",
       "Predicted Malignant              2                86"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_svc_classifier = svm.SVC(C=1)\n",
    "rbf_svc_clf_fit = rbf_svc_classifier.fit(X_train,y_train)\n",
    "rbf_predictions = rbf_svc_clf_fit.predict(X_test)\n",
    "\n",
    "\n",
    "rbf_cv_accuracy_score = cross_val_score(rbf_svc_classifier, bc_features, bc_target, cv=10).mean()\n",
    "\n",
    "print(str(rbf_cv_accuracy_score))\n",
    "print(confusion_matrix(y_test,rbf_predictions))\n",
    "print(classification_report(y_test,rbf_predictions))\n",
    "print(roc_auc_score(y_test, rbf_predictions))\n",
    "cm = confusion_matrix(y_test,rbf_predictions)\n",
    "cm_df = pd.DataFrame(cm, index=['Predicted Benign', 'Predicted Malignant'], \n",
    "                     columns=['Actual Benign', 'Actual Malignant'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly worse than the Voting Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

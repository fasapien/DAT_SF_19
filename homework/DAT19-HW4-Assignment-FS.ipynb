{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT 19: Homework 4 Assignment - SVMs, Trees, RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "The goal of this homework is to review and bring together what we have learned about Support Vector Machines, Decision Trees, Random Forests, and ensembles. \n",
    "\n",
    "Please do all your analysis to answer the questions below in this Jupyter notebook. Show your work.\n",
    "\n",
    "**Please submit your completed notebook by 6:30PM on Wednesday, February 17.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "Use the cancer_uci.csv dataset in the Data directory of our course repo. This is the [Breast Cancer Wisconsin](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)) dataset from the UCI ML Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Load the data and check for balance between the two classes. If the ratio is less than 60/40 rebalance the classes to 50/50. We've provided some help here to get you started.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign       458\n",
       "Malignant    241\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "canc = pd.read_csv(\"../data/cancer_uci.csv\", index_col=0)\n",
    "canc.head()\n",
    "canc.Class.value_counts()\n",
    "# What are the frequencies of each class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have imbalanced classes so we need to decide if we want to undersample, and take only 241 values from the Benign category, or oversample, and artificially inflate the volume of malignant data. First, let's convert to binary 1,0 for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    458\n",
       "1    241\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canc.Class = canc.Class.map({'Benign':0,'Malignant':1})\n",
    "canc.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To undersample, we would throw away almost half of our benign examples, which would greatly alter our dataset and we don't want to lose that much info. So let's oversample! Here is a pattern for how to oversample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916\n"
     ]
    }
   ],
   "source": [
    "# Separate your two classes:\n",
    "mal_example = canc[canc.Class == 1]\n",
    "benign_example = canc[canc.Class == 0]\n",
    "\n",
    "# Oversample the malignant class to have a 50/50 ratio:\n",
    "mal_over_example = mal_example.sample(458,replace=True)\n",
    "\n",
    "# Recombine the two frames:\n",
    "over_sample = pd.concat([mal_over_example,benign_example])\n",
    "\n",
    "# Sanity check the length:\n",
    "print len(over_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 916 entries, 104 to 695\n",
      "Data columns (total 11 columns):\n",
      "Sample_code_number             916 non-null int64\n",
      "Clump_Thickness                916 non-null int64\n",
      "Uniformity_of_Cell_Size        916 non-null int64\n",
      "Uniformity_of_Cell_Shape       916 non-null int64\n",
      "Marginal_Adhesion              916 non-null int64\n",
      "Single_Epithelial_Cell_Size    916 non-null int64\n",
      "Bare_Nuclei                    916 non-null object\n",
      "Bland_Chromatin                916 non-null int64\n",
      "Normal_Nucleoli                916 non-null int64\n",
      "Mitoses                        916 non-null int64\n",
      "Class                          916 non-null int64\n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 85.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 896 entries, 104 to 695\n",
      "Data columns (total 11 columns):\n",
      "Sample_code_number             896 non-null int64\n",
      "Clump_Thickness                896 non-null int64\n",
      "Uniformity_of_Cell_Size        896 non-null int64\n",
      "Uniformity_of_Cell_Shape       896 non-null int64\n",
      "Marginal_Adhesion              896 non-null int64\n",
      "Single_Epithelial_Cell_Size    896 non-null int64\n",
      "Bare_Nuclei                    896 non-null float64\n",
      "Bland_Chromatin                896 non-null int64\n",
      "Normal_Nucleoli                896 non-null int64\n",
      "Mitoses                        896 non-null int64\n",
      "Class                          896 non-null int64\n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 84.0 KB\n"
     ]
    }
   ],
   "source": [
    "over_sample.info()\n",
    "\n",
    "#'Bare_Nuclei' has 17 instances of non-numerical '?' \n",
    "over_sample['Bare_Nuclei'].value_counts()\n",
    "\n",
    "#Not sure if should drop or convert to mean... Gonna drop them\n",
    "over_sample = over_sample[over_sample['Bare_Nuclei'] != '?']\n",
    "over_sample['Bare_Nuclei'] = over_sample['Bare_Nuclei'].astype(float)\n",
    "over_sample.info()\n",
    "\n",
    "\n",
    "#over_sample['Bare_Nuclei'].replace(to_replace='nan')\n",
    "#over_sample['Bare_Nuclei'] = over_sample['Bare_Nuclei'].fillna(over_sample['Bare_Nuclei'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Are the features normalized? If not, use the scikit-learn standard scaler to normalize them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Train a linear SVM, using the cross validated accuracy as the score (use the scikit-learn method).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97218476903870155"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "\n",
    "bc_features = over_sample.drop(['Class','Sample_code_number'], axis=1)\n",
    "bc_target = over_sample['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bc_features, bc_target, test_size=.20, random_state=0)\n",
    "\n",
    "\n",
    "svc_classifier = svm.SVC(kernel='linear', C=1)\n",
    "svc_clf_fit = svc_classifier.fit(X_train,y_train)\n",
    "predictions = svc_clf_fit.predict(X_test)\n",
    "\n",
    "\n",
    "cross_val_scores = cross_val_score(svc_classifier, bc_features, bc_target, cv=5)\n",
    "cross_val_scores\n",
    "\n",
    "cv_accuracy_score = cross_val_scores.mean()\n",
    "cv_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Display the confusion matrix, classification report, and AUC.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90  2]\n",
      " [ 2 86]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98        92\n",
      "          1       0.98      0.98      0.98        88\n",
      "\n",
      "avg / total       0.98      0.98      0.98       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Repeat steps 2 through 4 using a Decision Tree model. Are the results better or worse than the SVM?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96438202247191018"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "tree_clf_fit = tree_clf.fit(X_train, y_train)\n",
    "tree_predictions = tree_clf_fit.predict(X_test)\n",
    "\n",
    "tree_cross_val_accuracy = cross_val_score(tree_clf, bc_features, bc_target, cv=5).mean()\n",
    "tree_cross_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[88  4]\n",
      " [ 3 85]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.96      0.96        92\n",
      "          1       0.96      0.97      0.96        88\n",
      "\n",
      "avg / total       0.96      0.96      0.96       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,tree_predictions))\n",
    "print(classification_report(y_test,tree_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Repeat steps 2 through 4 using a Random Forest model. Are the results better or worse than the SVM?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97886392009987522"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=5, n_estimators=100, max_features=3)\n",
    "rf_clf_fit = rf_clf.fit(X_train,y_train)\n",
    "\n",
    "rf_predictions = rf_clf_fit.predict(X_test)\n",
    "\n",
    "rf_cross_val_accuracy = cross_val_score(rf_clf, bc_features, bc_target, cv=5).mean()\n",
    "rf_cross_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90  2]\n",
      " [ 1 87]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.98        92\n",
      "          1       0.98      0.99      0.98        88\n",
      "\n",
      "avg / total       0.98      0.98      0.98       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,rf_predictions))\n",
    "print(classification_report(y_test,rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Credit Questions\n",
    "**The following questions are strongly encouraged, but not required for this homework assignment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) Combine the SVM and the Decision Tree model using the [Voting Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html). Are the results better than either of these base classifiers alone?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8) Train an SVM using the RBF kernel. Is this model better or worse?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT 19: Homework 2 Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "For Homework 2, we will build on the work we did with the Titanic dataset in Homework 1. In this assignment, we will build a logistic regression model to predict passenger survival.\n",
    "\n",
    "Please do all your analysis to answer the questions below in this Jupyter notebook. Show your work.\n",
    "\n",
    "**Please submit your completed notebook by 6:00PM on Monday, January 11.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "```\n",
    "VARIABLE DESCRIPTIONS:\n",
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "SPECIAL NOTES:\n",
    "Pclass is a proxy for socio-economic status (SES)\n",
    " 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "\n",
    "Age is in Years; Fractional if Age less than One (1)\n",
    " If the Age is Estimated, it is in the form xx.5\n",
    "\n",
    "With respect to the family relation variables (i.e. sibsp and parch)\n",
    "some relations were ignored.  The following are the definitions used\n",
    "for sibsp and parch.\n",
    "\n",
    "Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "Parent:   Mother or Father of Passenger Aboard Titanic\n",
    "Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "\n",
    "Other family relatives excluded from this study include cousins,\n",
    "nephews/nieces, aunts/uncles, and in-laws.  Some children travelled\n",
    "only with a nanny, therefore parch=0 for them.  As well, some\n",
    "travelled with very close friends or neighbors in a village, however,\n",
    "the definitions do not support such relations.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Create a logistic regression model on the Titanic dataset to predict the survival of passengers. Show your model output. Include coefficient values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Cleaning up the data\n",
    "titanic = pd.read_csv(\"titanic.csv\", header=0)\n",
    "\n",
    "\n",
    "#Changing gender to binary 0 - 1\n",
    "titanic.Sex.replace(['female', 'male'],[0,1],inplace=True)\n",
    "\n",
    "#Replacing missing ages with mean of age\n",
    "titanic.Age = titanic.Age.fillna(titanic.Age.mean())\n",
    "\n",
    "#Split passenger class into dummy variables\n",
    "pclass_dummies= pd.get_dummies(titanic.Pclass, prefix='Pclass')\n",
    "titanic = titanic.drop('Pclass', axis = 1)\n",
    "titanic = titanic.join(pclass_dummies)\n",
    "\n",
    "#Dropping the columns I will not use in my model, based on Homework 1 \n",
    "titanic_set = titanic.drop(['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin', 'Embarked'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived\n",
      "0            1         0\n",
      "1            2         1\n",
      "2            3         1\n",
      "3            4         1\n",
      "4            5         0\n",
      "5            6         0\n",
      "6            7         0\n",
      "7            8         0\n",
      "8            9         1\n",
      "9           10         1\n",
      "Actual Survival Rate (Training Set): 38.3838383838\n",
      "Model Survival Rate (Training Set): 36.9248035915\n",
      "Coefficient Values:  [[-1.30740997 -0.51138349 -0.35939488 -0.06380454  0.55168223  0.04629638\n",
      "  -0.51301058]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Model\n",
    "\n",
    "target = titanic_set.Survived\n",
    "features = titanic_set.drop('Survived',axis=1)\n",
    "new_features = StandardScaler().fit_transform(features)\n",
    "\n",
    "model_lr = LogisticRegression(C=1).fit(new_features, target)\n",
    "\n",
    "predictions = model_lr.predict(new_features)\n",
    "train_predictions = pd.DataFrame({\n",
    "        \"PassengerId\": titanic.PassengerId,\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "train_survival_rate = train_predictions.Survived.mean() * 100\n",
    "actual_train_survival_rate = titanic.Survived.mean() * 100\n",
    "\n",
    "print(train_predictions.head(10))\n",
    "print \"Actual Survival Rate (Training Set): \" + str(actual_train_survival_rate)\n",
    "print \"Model Survival Rate (Training Set): \" + str(train_survival_rate)\n",
    "print \"Coefficient Values: \", + model_lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Which features are predictive for this logistic regression? Explain your thinking. Do not simply cite model statistics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>[-1.30740997304]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>[-0.511383490162]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>[-0.359394880653]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parch</td>\n",
       "      <td>[-0.0638045360893]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>[0.551682234837]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>[0.0462963838301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>[-0.51301058007]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                   1\n",
       "0       Sex    [-1.30740997304]\n",
       "1       Age   [-0.511383490162]\n",
       "2     SibSp   [-0.359394880653]\n",
       "3     Parch  [-0.0638045360893]\n",
       "4  Pclass_1    [0.551682234837]\n",
       "5  Pclass_2   [0.0462963838301]\n",
       "6  Pclass_3    [-0.51301058007]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(features.columns, np.transpose(model_lr.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here is a quick and dirty table zipping together features and their coefficient values. Gender (sex) and passenger class are the clearest predictive features for this model, followed by age. Gender seems to have the most significant relationship to survival-- in this case, a being a man on the Titanic (represented by 1 in the training data) was far less likely to survive, indicated by the inverse relationship of sex to survival. If you flip the genders (1 for female, 0 for male), the relationship flips-- indicating that being female increases the likelihood that a person will survive. \n",
    "Passenger class also has an interesting relationship to the likelihood of a person's survival. The higher a person's passenger class, the more likely a person will survive-- First Class status (1) has a positive coefficient value (increased likelihood of receiving a positive value in the \"Survived\" column\") which drops for Second Class passengers and even more dramatically for Third Class passengers, changing to a negative coefficient value (inverse relationship to survival). These are very preliminary observations, however, as this analysis does not consider the impact of intersecting features (gender + class, for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Implement cross-validation for your logistic regression model. Select the number of folds. Explain your choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78900890931789802"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model_lr,features,target,cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honestly, I read some Q&A on StackOverflow and Quora, and I'm still not entirely sure if 10 is the correct number of folds or if I should have picked something different. I need to dig into this further, but for the homework, 10 folds seems to be a \"safe\" choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) In the hw-assignments director on the class github repo, there is a file called titanic-test.csv. What does your logistic regression model predict for these previously unseen (i.e. out of sample) passengers?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n",
      "5          897         0\n",
      "6          898         1\n",
      "7          899         0\n",
      "8          900         1\n",
      "9          901         0\n",
      "Model Survival Rate (Test): 37.0813397129\n"
     ]
    }
   ],
   "source": [
    "titanic_test = pd.read_csv(\"titanic-test.csv\", header=0)\n",
    "\n",
    "#Clean up titanic_test the same way\n",
    "titanic_test.Sex.replace(['female', 'male'],[0,1],inplace=True)\n",
    "titanic_test.Age = titanic_test.Age.fillna(titanic.Age.mean())\n",
    "pclass_dummies_test= pd.get_dummies(titanic_test.Pclass, prefix='Pclass')\n",
    "titanic_test = titanic_test.drop('Pclass', axis = 1)\n",
    "titanic_test = titanic_test.join(pclass_dummies_test)\n",
    "\n",
    "titanic_test_set = titanic_test.drop(['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin', 'Embarked'], axis=1)\n",
    "titanic_test_set_features = StandardScaler().fit_transform(titanic_test_set)\n",
    "\n",
    "\n",
    "model_lr = LogisticRegression(C=1).fit(new_features, target)\n",
    "\n",
    "test_predictions = model_lr.predict(titanic_test_set_features)\n",
    "test_predictions_viz = pd.DataFrame({\n",
    "        \"PassengerId\": titanic_test.PassengerId,\n",
    "        \"Survived\": test_predictions\n",
    "    })\n",
    "\n",
    "survival_rate_test = test_predictions_viz.Survived.mean() * 100\n",
    "\n",
    "print(test_predictions_viz.head(10))\n",
    "print \"Model Survival Rate (Test): \" + str(survival_rate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
